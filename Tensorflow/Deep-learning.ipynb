{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6567cf6-b479-4d28-863d-4732a42fdc66",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e48546-d573-47d5-94c2-bfac86d3dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b5682-9e36-44e9-8022-a5f65584efd6",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe12ea1-dc10-44f8-a9b4-f1ea768aba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5e02f8-5882-44ce-bf1a-9742d3359e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb79e658-7341-43a9-af01-3ee221ab0c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9fce016-f03c-4255-8fa6-6ad29304a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ccac8f-eeb1-4ca3-8217-4f78ccafdec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['label']=le.fit_transform(iris['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fb6270-b0a1-40b7-b830-9699ebd38974",
   "metadata": {},
   "source": [
    "## Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8ffddf-4610-4e96-9182-d3a6db558890",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=iris.drop(columns=['species','label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c54a1a14-04cf-4ff7-8c04-8819d067b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=iris['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4d2015b-31f4-42b6-9b7e-c4e670bc0d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5464d8fe-0ec2-402d-a553-5cd3f4b88e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145    2\n",
       "146    2\n",
       "147    2\n",
       "148    2\n",
       "149    2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0115350-3dc1-4147-ae18-3c13e6377fba",
   "metadata": {},
   "source": [
    "## Dividing into training and testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6723636-b28e-467b-8596-6e6af490f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=tts(x,y,test_size=0.2,stratify=y,random_state=10,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a1dd57f-a609-45c6-8b99-3a3794677eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f930ddb-335c-485a-b3ab-fac7db7fd19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=to_categorical(ytrain)\n",
    "ytest=to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e660a0-5d15-4407-b9b9-78bc4f1059eb",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abd3c20a-ad37-4668-b465-9170b6eb483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "831a9050-cd42-4c63-8f37-f327be632cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CDAC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(16, input_shape=(x.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5b6d5-0ccd-47d4-bdfe-0073319d4b0e",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37eeca91-b843-4d9f-b0eb-93f2b0502ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95660e54-9846-44ac-9ff4-40a919e5bbf8",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d477a9dc-ff4e-4a89-b34e-753914366e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3780 - loss: 1.9429 - val_accuracy: 0.3333 - val_loss: 1.5102\n",
      "Epoch 2/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3621 - loss: 1.5702 - val_accuracy: 0.4667 - val_loss: 1.2354\n",
      "Epoch 3/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3061 - loss: 1.3834 - val_accuracy: 0.3333 - val_loss: 1.1381\n",
      "Epoch 4/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2806 - loss: 1.2183 - val_accuracy: 0.3333 - val_loss: 1.1069\n",
      "Epoch 5/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3063 - loss: 1.2152 - val_accuracy: 0.3000 - val_loss: 1.0913\n",
      "Epoch 6/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1999 - loss: 1.1978 - val_accuracy: 0.3000 - val_loss: 1.0620\n",
      "Epoch 7/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4582 - loss: 1.0161 - val_accuracy: 0.4000 - val_loss: 1.0328\n",
      "Epoch 8/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4959 - loss: 1.0339 - val_accuracy: 0.4333 - val_loss: 1.0088\n",
      "Epoch 9/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5162 - loss: 0.9685 - val_accuracy: 0.4000 - val_loss: 0.9900\n",
      "Epoch 10/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5333 - loss: 1.0173 - val_accuracy: 0.3333 - val_loss: 0.9733\n",
      "Epoch 11/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5212 - loss: 0.9716 - val_accuracy: 0.5667 - val_loss: 0.9389\n",
      "Epoch 12/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4949 - loss: 0.9721 - val_accuracy: 0.6000 - val_loss: 0.8939\n",
      "Epoch 13/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5743 - loss: 0.9318 - val_accuracy: 0.6000 - val_loss: 0.8602\n",
      "Epoch 14/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6140 - loss: 0.9066 - val_accuracy: 0.7000 - val_loss: 0.8181\n",
      "Epoch 15/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5565 - loss: 0.8830 - val_accuracy: 0.6333 - val_loss: 0.7840\n",
      "Epoch 16/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5995 - loss: 0.8404 - val_accuracy: 0.6667 - val_loss: 0.7523\n",
      "Epoch 17/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6202 - loss: 0.8109 - val_accuracy: 0.6667 - val_loss: 0.7264\n",
      "Epoch 18/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6019 - loss: 0.7676 - val_accuracy: 0.6667 - val_loss: 0.6895\n",
      "Epoch 19/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5802 - loss: 0.8269 - val_accuracy: 0.7000 - val_loss: 0.6564\n",
      "Epoch 20/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6842 - loss: 0.6793 - val_accuracy: 0.7333 - val_loss: 0.6214\n",
      "Epoch 21/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6904 - loss: 0.6020 - val_accuracy: 0.7000 - val_loss: 0.5894\n",
      "Epoch 22/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7112 - loss: 0.6921 - val_accuracy: 0.7667 - val_loss: 0.5687\n",
      "Epoch 23/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6685 - loss: 0.6664 - val_accuracy: 0.8333 - val_loss: 0.5450\n",
      "Epoch 24/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7299 - loss: 0.6670 - val_accuracy: 0.8333 - val_loss: 0.5289\n",
      "Epoch 25/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6584 - loss: 0.6453 - val_accuracy: 0.8000 - val_loss: 0.5077\n",
      "Epoch 26/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7201 - loss: 0.5849 - val_accuracy: 0.8667 - val_loss: 0.4845\n",
      "Epoch 27/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.5741 - val_accuracy: 0.9667 - val_loss: 0.4687\n",
      "Epoch 28/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7408 - loss: 0.5561 - val_accuracy: 0.9000 - val_loss: 0.4530\n",
      "Epoch 29/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8204 - loss: 0.5340 - val_accuracy: 0.8333 - val_loss: 0.4404\n",
      "Epoch 30/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7676 - loss: 0.4954 - val_accuracy: 0.9000 - val_loss: 0.4297\n",
      "Epoch 31/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7132 - loss: 0.5363 - val_accuracy: 0.9000 - val_loss: 0.4203\n",
      "Epoch 32/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7801 - loss: 0.5144 - val_accuracy: 0.8667 - val_loss: 0.4063\n",
      "Epoch 33/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7291 - loss: 0.5385 - val_accuracy: 0.9667 - val_loss: 0.3959\n",
      "Epoch 34/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7905 - loss: 0.4876 - val_accuracy: 0.9667 - val_loss: 0.3882\n",
      "Epoch 35/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7874 - loss: 0.4879 - val_accuracy: 0.9333 - val_loss: 0.3797\n",
      "Epoch 36/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.4569 - val_accuracy: 0.9000 - val_loss: 0.3703\n",
      "Epoch 37/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8497 - loss: 0.4155 - val_accuracy: 0.9667 - val_loss: 0.3605\n",
      "Epoch 38/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7090 - loss: 0.5672 - val_accuracy: 0.9667 - val_loss: 0.3555\n",
      "Epoch 39/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8245 - loss: 0.4071 - val_accuracy: 0.9667 - val_loss: 0.3498\n",
      "Epoch 40/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7935 - loss: 0.4406 - val_accuracy: 0.9667 - val_loss: 0.3435\n",
      "Epoch 41/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8677 - loss: 0.3709 - val_accuracy: 0.9667 - val_loss: 0.3343\n",
      "Epoch 42/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 0.3784 - val_accuracy: 0.9667 - val_loss: 0.3256\n",
      "Epoch 43/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8592 - loss: 0.3826 - val_accuracy: 0.9667 - val_loss: 0.3193\n",
      "Epoch 44/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8434 - loss: 0.3682 - val_accuracy: 0.9667 - val_loss: 0.3118\n",
      "Epoch 45/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 0.3442 - val_accuracy: 0.9667 - val_loss: 0.3050\n",
      "Epoch 46/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8219 - loss: 0.3817 - val_accuracy: 0.9667 - val_loss: 0.3014\n",
      "Epoch 47/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9227 - loss: 0.3674 - val_accuracy: 0.9667 - val_loss: 0.2959\n",
      "Epoch 48/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9192 - loss: 0.3330 - val_accuracy: 0.9667 - val_loss: 0.2833\n",
      "Epoch 49/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7946 - loss: 0.3866 - val_accuracy: 0.9667 - val_loss: 0.2759\n",
      "Epoch 50/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8605 - loss: 0.3751 - val_accuracy: 0.9667 - val_loss: 0.2700\n",
      "Epoch 51/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9054 - loss: 0.3375 - val_accuracy: 0.9667 - val_loss: 0.2633\n",
      "Epoch 52/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9168 - loss: 0.2933 - val_accuracy: 0.9667 - val_loss: 0.2583\n",
      "Epoch 53/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.3840 - val_accuracy: 0.9667 - val_loss: 0.2523\n",
      "Epoch 54/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8520 - loss: 0.3640 - val_accuracy: 0.9667 - val_loss: 0.2485\n",
      "Epoch 55/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9014 - loss: 0.3232 - val_accuracy: 0.9667 - val_loss: 0.2452\n",
      "Epoch 56/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9264 - loss: 0.3190 - val_accuracy: 0.9667 - val_loss: 0.2428\n",
      "Epoch 57/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8360 - loss: 0.3673 - val_accuracy: 0.9667 - val_loss: 0.2388\n",
      "Epoch 58/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8632 - loss: 0.3178 - val_accuracy: 0.9667 - val_loss: 0.2345\n",
      "Epoch 59/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.3247 - val_accuracy: 0.9667 - val_loss: 0.2311\n",
      "Epoch 60/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.3121 - val_accuracy: 0.9667 - val_loss: 0.2225\n",
      "Epoch 61/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8954 - loss: 0.2625 - val_accuracy: 0.9667 - val_loss: 0.2197\n",
      "Epoch 62/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8695 - loss: 0.3298 - val_accuracy: 0.9667 - val_loss: 0.2187\n",
      "Epoch 63/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8459 - loss: 0.3227 - val_accuracy: 0.9667 - val_loss: 0.2165\n",
      "Epoch 64/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9006 - loss: 0.3042 - val_accuracy: 0.9667 - val_loss: 0.2167\n",
      "Epoch 65/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.2820 - val_accuracy: 0.9667 - val_loss: 0.2119\n",
      "Epoch 66/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9249 - loss: 0.2428 - val_accuracy: 0.9667 - val_loss: 0.2057\n",
      "Epoch 67/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9104 - loss: 0.3288 - val_accuracy: 0.9667 - val_loss: 0.2092\n",
      "Epoch 68/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9137 - loss: 0.2939 - val_accuracy: 0.9667 - val_loss: 0.1987\n",
      "Epoch 69/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9547 - loss: 0.2680 - val_accuracy: 0.9667 - val_loss: 0.1998\n",
      "Epoch 70/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8570 - loss: 0.3172 - val_accuracy: 0.9667 - val_loss: 0.1933\n",
      "Epoch 71/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8169 - loss: 0.3691 - val_accuracy: 0.9667 - val_loss: 0.2006\n",
      "Epoch 72/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8969 - loss: 0.2958 - val_accuracy: 0.9667 - val_loss: 0.1945\n",
      "Epoch 73/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9155 - loss: 0.2397 - val_accuracy: 0.9667 - val_loss: 0.1886\n",
      "Epoch 74/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8600 - loss: 0.3411 - val_accuracy: 0.9667 - val_loss: 0.1848\n",
      "Epoch 75/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9552 - loss: 0.2076 - val_accuracy: 0.9667 - val_loss: 0.1795\n",
      "Epoch 76/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8459 - loss: 0.3315 - val_accuracy: 0.9667 - val_loss: 0.1745\n",
      "Epoch 77/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9712 - loss: 0.2028 - val_accuracy: 0.9667 - val_loss: 0.1672\n",
      "Epoch 78/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9015 - loss: 0.2520 - val_accuracy: 0.9667 - val_loss: 0.1590\n",
      "Epoch 79/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9418 - loss: 0.2407 - val_accuracy: 0.9667 - val_loss: 0.1560\n",
      "Epoch 80/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8959 - loss: 0.2442 - val_accuracy: 0.9667 - val_loss: 0.1604\n",
      "Epoch 81/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8799 - loss: 0.2553 - val_accuracy: 0.9667 - val_loss: 0.1594\n",
      "Epoch 82/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9296 - loss: 0.2445 - val_accuracy: 0.9667 - val_loss: 0.1554\n",
      "Epoch 83/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9539 - loss: 0.1956 - val_accuracy: 0.9667 - val_loss: 0.1519\n",
      "Epoch 84/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9001 - loss: 0.2632 - val_accuracy: 0.9667 - val_loss: 0.1488\n",
      "Epoch 85/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9407 - loss: 0.2231 - val_accuracy: 0.9667 - val_loss: 0.1481\n",
      "Epoch 86/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9388 - loss: 0.2232 - val_accuracy: 1.0000 - val_loss: 0.1441\n",
      "Epoch 87/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8737 - loss: 0.2897 - val_accuracy: 0.9667 - val_loss: 0.1384\n",
      "Epoch 88/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9223 - loss: 0.2195 - val_accuracy: 1.0000 - val_loss: 0.1377\n",
      "Epoch 89/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8875 - loss: 0.2656 - val_accuracy: 1.0000 - val_loss: 0.1386\n",
      "Epoch 90/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8695 - loss: 0.3100 - val_accuracy: 1.0000 - val_loss: 0.1443\n",
      "Epoch 91/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9170 - loss: 0.2520 - val_accuracy: 0.9667 - val_loss: 0.1381\n",
      "Epoch 92/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9414 - loss: 0.2410 - val_accuracy: 0.9667 - val_loss: 0.1355\n",
      "Epoch 93/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9561 - loss: 0.2034 - val_accuracy: 1.0000 - val_loss: 0.1337\n",
      "Epoch 94/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9548 - loss: 0.1937 - val_accuracy: 0.9667 - val_loss: 0.1334\n",
      "Epoch 95/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9109 - loss: 0.1995 - val_accuracy: 0.9667 - val_loss: 0.1310\n",
      "Epoch 96/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9641 - loss: 0.1682 - val_accuracy: 0.9667 - val_loss: 0.1277\n",
      "Epoch 97/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8323 - loss: 0.2812 - val_accuracy: 0.9667 - val_loss: 0.1257\n",
      "Epoch 98/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8899 - loss: 0.2378 - val_accuracy: 0.9667 - val_loss: 0.1222\n",
      "Epoch 99/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.2251 - val_accuracy: 0.9667 - val_loss: 0.1220\n",
      "Epoch 100/100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9384 - loss: 0.2040 - val_accuracy: 1.0000 - val_loss: 0.1264\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xtrain, ytrain,\n",
    "                    validation_data=(xtest, ytest),\n",
    "                    epochs=100,\n",
    "                    batch_size=8,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1afe0f-b692-4081-99ea-9f5383a4abd0",
   "metadata": {},
   "source": [
    "## Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11007941-ed29-474d-bfee-12a4a3626438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CDAC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\visualkeras\\layered.py:86: UserWarning: The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\n",
      "  warnings.warn(\"The legend_text_spacing_offset parameter is deprecated and will be removed in a future release.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=137x93>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import visualkeras as vk\n",
    "vk.layered_view(model,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad13e585-dc0e-44cb-aa75-9cdedae7e438",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc0bfa23-941a-4cea-8490-504b90bd3205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.1264\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b88f1d5f-0836-4091-9c28-b42daaef10a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12640148401260376"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c751ed3c-1c56-44c2-8d38-9883b921fe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ecd2d-7408-4c6d-8726-99a3ebfedcde",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a0f7be4-b9a8-4810-bdeb-60b52492c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4973469-c0fe-44ee-921b-ae7fb213fac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(np.array([[5.1,3.5,1.4,0.2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "654ccde0-1647-44a1-a436-04ef77051c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d6bbd7b-66bd-4e64-8fcc-c68afc8e1f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e06b7-3320-4dd3-9fff-180901119326",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ad886dc-64cb-44dc-9457-3a5b3d615d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mark=pd.read_csv('score_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b93c107-6325-4556-8bd2-6ddb48551b57",
   "metadata": {},
   "source": [
    "## Dividing into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76e94c8e-462f-47d3-8867-204003eb7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=mark[['Hours']]\n",
    "y1=mark['Scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5588dd-e740-45de-ba3b-4a06b48fde74",
   "metadata": {},
   "source": [
    "## Splitting into train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "185bf491-9109-469d-923c-15668fbe7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain1,xtest1,ytrain1,ytest1=tts(x1,y1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dffd747-4eb0-4a14-b952-f01886f2a7e7",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0fef9dd-a2f5-4717-a5c6-bbb8bade70f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CDAC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "reg=Sequential()\n",
    "reg.add(Dense(16, input_dim=1, activation='relu'))\n",
    "reg.add(Dense(8, activation='relu'))\n",
    "reg.add(Dense(1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a1c957-6412-4834-947b-84195546c9db",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6e6bf0b-bac6-46d6-a07b-ab034e6eb9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95566505-b054-4d82-91dc-a97eace6060e",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b94cf88-9c16-44f3-bce7-bfeb79c1441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 3241.6550 - mae: 51.2460 - val_loss: 5233.7905 - val_mae: 68.4520\n",
      "Epoch 2/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3200.4976 - mae: 51.1459 - val_loss: 5203.7344 - val_mae: 68.2531\n",
      "Epoch 3/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3017.3865 - mae: 49.4842 - val_loss: 5174.2744 - val_mae: 68.0577\n",
      "Epoch 4/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3366.6646 - mae: 52.2270 - val_loss: 5145.0005 - val_mae: 67.8629\n",
      "Epoch 5/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3107.9919 - mae: 50.3089 - val_loss: 5115.9873 - val_mae: 67.6694\n",
      "Epoch 6/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3195.7705 - mae: 50.7586 - val_loss: 5086.9531 - val_mae: 67.4752\n",
      "Epoch 7/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3085.6028 - mae: 50.1953 - val_loss: 5058.0166 - val_mae: 67.2819\n",
      "Epoch 8/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3164.2573 - mae: 50.8034 - val_loss: 5030.8579 - val_mae: 67.1047\n",
      "Epoch 9/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3026.6135 - mae: 49.3446 - val_loss: 5015.4131 - val_mae: 67.0017\n",
      "Epoch 10/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2993.2415 - mae: 49.0966 - val_loss: 5000.8706 - val_mae: 66.9033\n",
      "Epoch 11/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2984.6846 - mae: 49.1591 - val_loss: 4985.8960 - val_mae: 66.8018\n",
      "Epoch 12/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2942.6978 - mae: 49.0026 - val_loss: 4970.6865 - val_mae: 66.6986\n",
      "Epoch 13/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3191.2695 - mae: 51.5984 - val_loss: 4955.0396 - val_mae: 66.5922\n",
      "Epoch 14/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2937.5085 - mae: 48.7320 - val_loss: 4939.3984 - val_mae: 66.4857\n",
      "Epoch 15/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3315.4795 - mae: 52.0447 - val_loss: 4923.6890 - val_mae: 66.3786\n",
      "Epoch 16/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2974.1377 - mae: 49.0004 - val_loss: 4908.3452 - val_mae: 66.2738\n",
      "Epoch 17/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2988.6848 - mae: 49.2054 - val_loss: 4892.9492 - val_mae: 66.1684\n",
      "Epoch 18/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2793.4792 - mae: 47.4434 - val_loss: 4877.5459 - val_mae: 66.0629\n",
      "Epoch 19/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2941.2041 - mae: 49.0491 - val_loss: 4861.9087 - val_mae: 65.9555\n",
      "Epoch 20/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3136.8369 - mae: 50.6375 - val_loss: 4845.9795 - val_mae: 65.8460\n",
      "Epoch 21/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2968.5227 - mae: 49.1475 - val_loss: 4830.0024 - val_mae: 65.7360\n",
      "Epoch 22/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3035.2476 - mae: 49.7623 - val_loss: 4813.6758 - val_mae: 65.6233\n",
      "Epoch 23/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 2804.9136 - mae: 47.5218 - val_loss: 4797.7295 - val_mae: 65.5127\n",
      "Epoch 24/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3041.0891 - mae: 50.1071 - val_loss: 4780.6377 - val_mae: 65.3948\n",
      "Epoch 25/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3072.5649 - mae: 49.8311 - val_loss: 4763.8057 - val_mae: 65.2781\n",
      "Epoch 26/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2964.5481 - mae: 49.3649 - val_loss: 4746.7969 - val_mae: 65.1599\n",
      "Epoch 27/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2926.4890 - mae: 48.6530 - val_loss: 4729.4077 - val_mae: 65.0389\n",
      "Epoch 28/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2874.5237 - mae: 47.9616 - val_loss: 4711.6421 - val_mae: 64.9150\n",
      "Epoch 29/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3110.3938 - mae: 50.7958 - val_loss: 4693.6240 - val_mae: 64.7891\n",
      "Epoch 30/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2781.2383 - mae: 47.5153 - val_loss: 4675.7607 - val_mae: 64.6640\n",
      "Epoch 31/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2838.6401 - mae: 48.1593 - val_loss: 4657.3389 - val_mae: 64.5350\n",
      "Epoch 32/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2930.1108 - mae: 48.6008 - val_loss: 4638.6475 - val_mae: 64.4039\n",
      "Epoch 33/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2764.8682 - mae: 47.1831 - val_loss: 4619.7212 - val_mae: 64.2710\n",
      "Epoch 34/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2823.2476 - mae: 47.6843 - val_loss: 4600.4746 - val_mae: 64.1359\n",
      "Epoch 35/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2762.2600 - mae: 47.3622 - val_loss: 4581.3867 - val_mae: 64.0019\n",
      "Epoch 36/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2967.3008 - mae: 48.9247 - val_loss: 4562.5576 - val_mae: 63.8690\n",
      "Epoch 37/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2696.5801 - mae: 46.6326 - val_loss: 4543.7163 - val_mae: 63.7358\n",
      "Epoch 38/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2676.5557 - mae: 46.1557 - val_loss: 4524.5430 - val_mae: 63.5998\n",
      "Epoch 39/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2757.9280 - mae: 47.0180 - val_loss: 4505.1929 - val_mae: 63.4619\n",
      "Epoch 40/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2655.1257 - mae: 46.6384 - val_loss: 4485.5059 - val_mae: 63.3213\n",
      "Epoch 41/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2747.8743 - mae: 47.2150 - val_loss: 4465.1650 - val_mae: 63.1757\n",
      "Epoch 42/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2689.7688 - mae: 46.4445 - val_loss: 4444.8657 - val_mae: 63.0298\n",
      "Epoch 43/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2811.0264 - mae: 47.9588 - val_loss: 4424.0107 - val_mae: 62.8798\n",
      "Epoch 44/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2859.8398 - mae: 48.3356 - val_loss: 4402.6519 - val_mae: 62.7260\n",
      "Epoch 45/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2699.7908 - mae: 47.0187 - val_loss: 4381.1553 - val_mae: 62.5711\n",
      "Epoch 46/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2751.3936 - mae: 47.4745 - val_loss: 4359.1782 - val_mae: 62.4122\n",
      "Epoch 47/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2814.0825 - mae: 47.8902 - val_loss: 4336.8052 - val_mae: 62.2497\n",
      "Epoch 48/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2642.4395 - mae: 46.0012 - val_loss: 4314.4326 - val_mae: 62.0868\n",
      "Epoch 49/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2615.9243 - mae: 46.1560 - val_loss: 4291.6235 - val_mae: 61.9201\n",
      "Epoch 50/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2734.4673 - mae: 47.2653 - val_loss: 4268.0610 - val_mae: 61.7475\n",
      "Epoch 51/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2779.6890 - mae: 47.0829 - val_loss: 4244.1587 - val_mae: 61.5720\n",
      "Epoch 52/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2736.3394 - mae: 47.1676 - val_loss: 4220.1768 - val_mae: 61.3954\n",
      "Epoch 53/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2649.2715 - mae: 46.5079 - val_loss: 4195.9360 - val_mae: 61.2164\n",
      "Epoch 54/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2571.7642 - mae: 45.8222 - val_loss: 4171.2266 - val_mae: 61.0333\n",
      "Epoch 55/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2841.3833 - mae: 48.1361 - val_loss: 4145.7788 - val_mae: 60.8442\n",
      "Epoch 56/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2565.3191 - mae: 45.3859 - val_loss: 4120.4014 - val_mae: 60.6551\n",
      "Epoch 57/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2573.6758 - mae: 45.5648 - val_loss: 4094.2722 - val_mae: 60.4598\n",
      "Epoch 58/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2480.3875 - mae: 44.9912 - val_loss: 4067.8618 - val_mae: 60.2617\n",
      "Epoch 59/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2488.3857 - mae: 45.0659 - val_loss: 4040.7319 - val_mae: 60.0575\n",
      "Epoch 60/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2439.1514 - mae: 44.2706 - val_loss: 4013.2070 - val_mae: 59.8497\n",
      "Epoch 61/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2489.5098 - mae: 44.9765 - val_loss: 3985.1548 - val_mae: 59.6371\n",
      "Epoch 62/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2422.1345 - mae: 44.1203 - val_loss: 3956.9028 - val_mae: 59.4224\n",
      "Epoch 63/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2564.6763 - mae: 45.7986 - val_loss: 3927.8394 - val_mae: 59.2006\n",
      "Epoch 64/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2514.0669 - mae: 45.3216 - val_loss: 3898.3992 - val_mae: 58.9751\n",
      "Epoch 65/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2523.0415 - mae: 45.5543 - val_loss: 3868.4907 - val_mae: 58.7451\n",
      "Epoch 66/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2418.9507 - mae: 43.9886 - val_loss: 3838.5164 - val_mae: 58.5137\n",
      "Epoch 67/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2296.1545 - mae: 42.6986 - val_loss: 3807.9570 - val_mae: 58.2769\n",
      "Epoch 68/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2404.7417 - mae: 44.0499 - val_loss: 3776.4578 - val_mae: 58.0318\n",
      "Epoch 69/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2476.3318 - mae: 44.9739 - val_loss: 3744.5652 - val_mae: 57.7826\n",
      "Epoch 70/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2311.8008 - mae: 42.8880 - val_loss: 3712.4297 - val_mae: 57.5304\n",
      "Epoch 71/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2345.6152 - mae: 43.5908 - val_loss: 3679.3867 - val_mae: 57.2699\n",
      "Epoch 72/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2289.5425 - mae: 42.7517 - val_loss: 3645.7273 - val_mae: 57.0034\n",
      "Epoch 73/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2446.3257 - mae: 44.8666 - val_loss: 3611.2195 - val_mae: 56.7289\n",
      "Epoch 74/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2250.0933 - mae: 42.5940 - val_loss: 3576.6255 - val_mae: 56.4524\n",
      "Epoch 75/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2130.5779 - mae: 41.3631 - val_loss: 3541.4153 - val_mae: 56.1696\n",
      "Epoch 76/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2203.5520 - mae: 42.1242 - val_loss: 3505.4363 - val_mae: 55.8792\n",
      "Epoch 77/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1990.1406 - mae: 39.9092 - val_loss: 3469.4485 - val_mae: 55.5873\n",
      "Epoch 78/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2108.1980 - mae: 41.0388 - val_loss: 3432.0203 - val_mae: 55.2820\n",
      "Epoch 79/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2178.4202 - mae: 41.9279 - val_loss: 3393.6218 - val_mae: 54.9671\n",
      "Epoch 80/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 2092.1592 - mae: 40.9390 - val_loss: 3355.2844 - val_mae: 54.6508\n",
      "Epoch 81/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2216.3970 - mae: 42.2380 - val_loss: 3317.0039 - val_mae: 54.3332\n",
      "Epoch 82/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1951.5701 - mae: 39.3303 - val_loss: 3278.7446 - val_mae: 54.0139\n",
      "Epoch 83/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2146.3848 - mae: 41.7857 - val_loss: 3239.0847 - val_mae: 53.6810\n",
      "Epoch 84/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2031.1768 - mae: 40.5178 - val_loss: 3199.7852 - val_mae: 53.3490\n",
      "Epoch 85/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2007.1842 - mae: 40.4084 - val_loss: 3160.1479 - val_mae: 53.0121\n",
      "Epoch 86/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2023.7028 - mae: 40.5424 - val_loss: 3119.9556 - val_mae: 52.6683\n",
      "Epoch 87/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1902.1804 - mae: 39.0039 - val_loss: 3079.7207 - val_mae: 52.3220\n",
      "Epoch 88/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1847.0383 - mae: 38.5672 - val_loss: 3038.4019 - val_mae: 51.9640\n",
      "Epoch 89/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1883.8430 - mae: 38.7504 - val_loss: 2996.4414 - val_mae: 51.5978\n",
      "Epoch 90/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1732.5671 - mae: 37.1467 - val_loss: 2954.3926 - val_mae: 51.2283\n",
      "Epoch 91/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1699.2024 - mae: 36.8085 - val_loss: 2911.2703 - val_mae: 50.8466\n",
      "Epoch 92/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1818.1052 - mae: 38.2484 - val_loss: 2866.6375 - val_mae: 50.4486\n",
      "Epoch 93/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1803.1428 - mae: 38.0619 - val_loss: 2822.1655 - val_mae: 50.0489\n",
      "Epoch 94/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1631.6187 - mae: 35.6778 - val_loss: 2778.4309 - val_mae: 49.6527\n",
      "Epoch 95/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1795.5701 - mae: 37.7554 - val_loss: 2733.8638 - val_mae: 49.2458\n",
      "Epoch 96/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1763.3315 - mae: 37.6372 - val_loss: 2689.6262 - val_mae: 48.8387\n",
      "Epoch 97/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1744.7959 - mae: 37.2582 - val_loss: 2644.8828 - val_mae: 48.4235\n",
      "Epoch 98/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1561.1160 - mae: 35.0100 - val_loss: 2600.4312 - val_mae: 48.0074\n",
      "Epoch 99/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1703.2136 - mae: 36.8462 - val_loss: 2555.6003 - val_mae: 47.5842\n",
      "Epoch 100/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1616.9467 - mae: 35.7571 - val_loss: 2510.8176 - val_mae: 47.1576\n",
      "Epoch 101/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1551.1367 - mae: 35.3499 - val_loss: 2465.7087 - val_mae: 46.7240\n",
      "Epoch 102/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1612.4149 - mae: 35.7905 - val_loss: 2420.1443 - val_mae: 46.2820\n",
      "Epoch 103/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1540.9933 - mae: 35.0496 - val_loss: 2374.8140 - val_mae: 45.8380\n",
      "Epoch 104/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1464.1971 - mae: 34.1453 - val_loss: 2330.0396 - val_mae: 45.3953\n",
      "Epoch 105/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1495.3556 - mae: 34.2107 - val_loss: 2285.1616 - val_mae: 44.9472\n",
      "Epoch 106/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1447.5469 - mae: 34.2417 - val_loss: 2239.5500 - val_mae: 44.4871\n",
      "Epoch 107/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1430.3289 - mae: 33.7918 - val_loss: 2193.5132 - val_mae: 44.0180\n",
      "Epoch 108/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1343.7563 - mae: 32.7595 - val_loss: 2147.3918 - val_mae: 43.5430\n",
      "Epoch 109/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1340.9817 - mae: 32.4507 - val_loss: 2100.8745 - val_mae: 43.0586\n",
      "Epoch 110/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1301.0875 - mae: 32.0237 - val_loss: 2054.0601 - val_mae: 42.5656\n",
      "Epoch 111/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1260.8394 - mae: 31.5960 - val_loss: 2007.2019 - val_mae: 42.0664\n",
      "Epoch 112/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1295.0664 - mae: 31.9304 - val_loss: 1960.7604 - val_mae: 41.5657\n",
      "Epoch 113/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1187.8632 - mae: 30.2995 - val_loss: 1915.0769 - val_mae: 41.0673\n",
      "Epoch 114/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1216.6372 - mae: 30.8821 - val_loss: 1869.0059 - val_mae: 40.5585\n",
      "Epoch 115/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1130.1826 - mae: 29.8055 - val_loss: 1822.9734 - val_mae: 40.0438\n",
      "Epoch 116/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1217.2487 - mae: 31.0664 - val_loss: 1777.0012 - val_mae: 39.5231\n",
      "Epoch 117/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1185.0073 - mae: 30.5190 - val_loss: 1732.4027 - val_mae: 39.0114\n",
      "Epoch 118/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1032.1758 - mae: 28.2579 - val_loss: 1688.3418 - val_mae: 38.4992\n",
      "Epoch 119/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1051.8984 - mae: 28.8418 - val_loss: 1643.6653 - val_mae: 37.9730\n",
      "Epoch 120/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 988.9042 - mae: 27.6638 - val_loss: 1598.9838 - val_mae: 37.4394\n",
      "Epoch 121/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1033.3074 - mae: 28.5121 - val_loss: 1553.9077 - val_mae: 36.8934\n",
      "Epoch 122/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1015.6993 - mae: 28.2073 - val_loss: 1509.8044 - val_mae: 36.3514\n",
      "Epoch 123/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 908.5156 - mae: 26.5336 - val_loss: 1466.2531 - val_mae: 35.8082\n",
      "Epoch 124/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 887.0082 - mae: 26.1902 - val_loss: 1422.8477 - val_mae: 35.2586\n",
      "Epoch 125/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 969.3287 - mae: 27.7552 - val_loss: 1379.3052 - val_mae: 34.6988\n",
      "Epoch 126/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 870.4670 - mae: 25.9593 - val_loss: 1337.6803 - val_mae: 34.1551\n",
      "Epoch 127/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 856.7037 - mae: 25.7815 - val_loss: 1296.0334 - val_mae: 33.6025\n",
      "Epoch 128/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 819.8790 - mae: 25.1167 - val_loss: 1254.3855 - val_mae: 33.0408\n",
      "Epoch 129/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 779.2007 - mae: 24.4674 - val_loss: 1213.2990 - val_mae: 32.4773\n",
      "Epoch 130/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 726.3108 - mae: 23.3925 - val_loss: 1173.1324 - val_mae: 31.9169\n",
      "Epoch 131/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 706.0908 - mae: 23.0636 - val_loss: 1133.2084 - val_mae: 31.3502\n",
      "Epoch 132/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 732.3446 - mae: 23.5540 - val_loss: 1093.9447 - val_mae: 30.7829\n",
      "Epoch 133/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 708.4405 - mae: 23.1919 - val_loss: 1055.5321 - val_mae: 30.2178\n",
      "Epoch 134/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 678.2602 - mae: 22.6449 - val_loss: 1017.5993 - val_mae: 29.6493\n",
      "Epoch 135/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 666.4319 - mae: 22.4551 - val_loss: 980.5231 - val_mae: 29.0832\n",
      "Epoch 136/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 590.2392 - mae: 20.8524 - val_loss: 944.6906 - val_mae: 28.5255\n",
      "Epoch 137/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 618.7006 - mae: 21.8297 - val_loss: 908.8714 - val_mae: 27.9572\n",
      "Epoch 138/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 593.1533 - mae: 21.1332 - val_loss: 874.2469 - val_mae: 27.3969\n",
      "Epoch 139/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 544.8533 - mae: 20.1958 - val_loss: 840.4034 - val_mae: 26.8381\n",
      "Epoch 140/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 517.8066 - mae: 19.7481 - val_loss: 807.0680 - val_mae: 26.2763\n",
      "Epoch 141/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 537.6270 - mae: 20.0695 - val_loss: 774.0706 - val_mae: 25.7085\n",
      "Epoch 142/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 504.0105 - mae: 19.4675 - val_loss: 742.3589 - val_mae: 25.1509\n",
      "Epoch 143/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 479.7955 - mae: 18.6670 - val_loss: 711.7211 - val_mae: 24.6005\n",
      "Epoch 144/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 465.4453 - mae: 18.5566 - val_loss: 681.7164 - val_mae: 24.0496\n",
      "Epoch 145/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 462.8828 - mae: 18.5950 - val_loss: 652.5333 - val_mae: 23.5016\n",
      "Epoch 146/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 407.7423 - mae: 17.2395 - val_loss: 624.1261 - val_mae: 22.9559\n",
      "Epoch 147/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 390.9721 - mae: 16.9143 - val_loss: 596.0289 - val_mae: 22.4035\n",
      "Epoch 148/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 379.2415 - mae: 16.5744 - val_loss: 568.6217 - val_mae: 21.8516\n",
      "Epoch 149/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 370.5677 - mae: 16.0480 - val_loss: 541.9227 - val_mae: 21.3005\n",
      "Epoch 150/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 367.0317 - mae: 16.2829 - val_loss: 515.9821 - val_mae: 20.7514\n",
      "Epoch 151/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 331.6252 - mae: 15.4743 - val_loss: 491.2237 - val_mae: 20.2138\n",
      "Epoch 152/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 344.7738 - mae: 15.7806 - val_loss: 467.0056 - val_mae: 19.6742\n",
      "Epoch 153/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 317.0701 - mae: 14.9057 - val_loss: 443.9011 - val_mae: 19.1456\n",
      "Epoch 154/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 292.4373 - mae: 14.3648 - val_loss: 421.7501 - val_mae: 18.6252\n",
      "Epoch 155/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 281.0351 - mae: 13.9293 - val_loss: 400.1464 - val_mae: 18.1037\n",
      "Epoch 156/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 250.9677 - mae: 12.9256 - val_loss: 379.4731 - val_mae: 17.5906\n",
      "Epoch 157/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 251.0498 - mae: 13.1806 - val_loss: 359.1190 - val_mae: 17.0708\n",
      "Epoch 158/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 225.8277 - mae: 12.2368 - val_loss: 339.4962 - val_mae: 16.5549\n",
      "Epoch 159/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 232.0723 - mae: 12.6579 - val_loss: 320.2940 - val_mae: 16.0345\n",
      "Epoch 160/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 199.0056 - mae: 11.4390 - val_loss: 302.2334 - val_mae: 15.5297\n",
      "Epoch 161/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 197.2720 - mae: 11.5184 - val_loss: 285.0429 - val_mae: 15.0340\n",
      "Epoch 162/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 189.3544 - mae: 11.2906 - val_loss: 268.8215 - val_mae: 14.5514\n",
      "Epoch 163/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 174.6913 - mae: 10.6262 - val_loss: 253.1937 - val_mae: 14.0714\n",
      "Epoch 164/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 164.3397 - mae: 10.4779 - val_loss: 238.1775 - val_mae: 13.5949\n",
      "Epoch 165/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 165.6400 - mae: 10.4556 - val_loss: 223.8120 - val_mae: 13.1235\n",
      "Epoch 166/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 147.5585 - mae: 9.7804 - val_loss: 210.3042 - val_mae: 12.6649\n",
      "Epoch 167/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 135.7160 - mae: 9.2740 - val_loss: 197.5708 - val_mae: 12.2176\n",
      "Epoch 168/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 124.9046 - mae: 9.0181 - val_loss: 185.3328 - val_mae: 11.7724\n",
      "Epoch 169/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 125.8335 - mae: 9.1713 - val_loss: 173.5966 - val_mae: 11.3299\n",
      "Epoch 170/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 124.8479 - mae: 8.9880 - val_loss: 162.6521 - val_mae: 10.9018\n",
      "Epoch 171/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 109.2941 - mae: 8.4645 - val_loss: 152.5216 - val_mae: 10.4909\n",
      "Epoch 172/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 98.9844 - mae: 8.0751 - val_loss: 142.9294 - val_mae: 10.0931\n",
      "Epoch 173/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 100.8701 - mae: 8.2211 - val_loss: 133.5865 - val_mae: 9.7096\n",
      "Epoch 174/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 88.9899 - mae: 7.5670 - val_loss: 124.9187 - val_mae: 9.3396\n",
      "Epoch 175/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 80.6098 - mae: 7.2698 - val_loss: 116.7770 - val_mae: 8.9949\n",
      "Epoch 176/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 83.3419 - mae: 7.4997 - val_loss: 109.0076 - val_mae: 8.6626\n",
      "Epoch 177/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 79.8543 - mae: 7.2697 - val_loss: 101.6954 - val_mae: 8.3365\n",
      "Epoch 178/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 69.1412 - mae: 6.7561 - val_loss: 94.9203 - val_mae: 8.0213\n",
      "Epoch 179/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 67.8608 - mae: 6.6781 - val_loss: 88.5598 - val_mae: 7.7124\n",
      "Epoch 180/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 67.1670 - mae: 6.6320 - val_loss: 82.5954 - val_mae: 7.4144\n",
      "Epoch 181/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 63.4715 - mae: 6.5618 - val_loss: 77.1100 - val_mae: 7.1348\n",
      "Epoch 182/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 59.1070 - mae: 6.3323 - val_loss: 72.0728 - val_mae: 6.8663\n",
      "Epoch 183/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 51.5022 - mae: 5.7995 - val_loss: 67.4883 - val_mae: 6.6467\n",
      "Epoch 184/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 49.5344 - mae: 5.7903 - val_loss: 63.2296 - val_mae: 6.4350\n",
      "Epoch 185/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 47.5730 - mae: 5.7097 - val_loss: 59.2545 - val_mae: 6.2277\n",
      "Epoch 186/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 45.4416 - mae: 5.5765 - val_loss: 55.5977 - val_mae: 6.0282\n",
      "Epoch 187/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 42.3508 - mae: 5.2744 - val_loss: 52.2500 - val_mae: 5.8364\n",
      "Epoch 188/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 41.5038 - mae: 5.3583 - val_loss: 49.1210 - val_mae: 5.6490\n",
      "Epoch 189/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 37.2600 - mae: 5.1317 - val_loss: 46.3000 - val_mae: 5.4768\n",
      "Epoch 190/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 37.9164 - mae: 5.1301 - val_loss: 43.6704 - val_mae: 5.3147\n",
      "Epoch 191/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 37.3945 - mae: 5.1707 - val_loss: 41.2198 - val_mae: 5.1557\n",
      "Epoch 192/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 35.2651 - mae: 4.9763 - val_loss: 39.0273 - val_mae: 5.0132\n",
      "Epoch 193/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 32.3364 - mae: 4.7023 - val_loss: 37.0232 - val_mae: 4.9038\n",
      "Epoch 194/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 30.3291 - mae: 4.6653 - val_loss: 35.2060 - val_mae: 4.8031\n",
      "Epoch 195/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 29.4822 - mae: 4.5448 - val_loss: 33.5865 - val_mae: 4.7086\n",
      "Epoch 196/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 27.2678 - mae: 4.3714 - val_loss: 32.1079 - val_mae: 4.6176\n",
      "Epoch 197/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 29.0131 - mae: 4.5180 - val_loss: 30.7341 - val_mae: 4.5285\n",
      "Epoch 198/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 26.7209 - mae: 4.3905 - val_loss: 29.4926 - val_mae: 4.4435\n",
      "Epoch 199/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 26.8290 - mae: 4.3786 - val_loss: 28.3318 - val_mae: 4.3595\n",
      "Epoch 200/200\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 24.7864 - mae: 4.1628 - val_loss: 27.2696 - val_mae: 4.2780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cf64fc4ad0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(xtrain1,ytrain1,validation_data=(xtest1, ytest1),\n",
    "                    epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce7ff3-d1f2-4327-a762-550c7cc32665",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb913102-f78d-494a-ad4c-b3d7b1c44443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 27.2696 - mae: 4.2780\n",
      "4.278021812438965\n"
     ]
    }
   ],
   "source": [
    "loss1, mae1 = reg.evaluate(xtest1, ytest1)\n",
    "print(mae1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aa0e15-e9b2-47ea-8b8a-c37e97126237",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c28f973-6e82-433b-af2d-7644ecf43bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[80.14354]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(np.array([[8.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c6894-1fd3-4fa9-a67f-63030aca655f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
